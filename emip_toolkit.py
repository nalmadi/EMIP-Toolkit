"""
The EMIP Toolkit (EMTK) can be used under the CC 4.0 license
(https://creativecommons.org/licenses/by/4.0/)

Authors:
Naser Al Madi (nsalmadi@colby.edu)
Ricky Peng (siyuan.peng@colby.edu)

"""

import math
import os
import statistics

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from PIL import Image, ImageDraw, ImageEnhance, ImageFont
import requests, zipfile
from clint.textui import progress
from tqdm import tqdm

# Dictionary for datasets Key = dataset_name, Value = [url, is_zipped, citation]
data_dictionary = {'EMIP' : ['https://osf.io/j6vt3/download', False, 'https://dl.acm.org/doi/abs/10.1145/3448018.3457425']}

class Fixation:
    """ Basic container for storing Fixation data """

    def __init__(self, trial_id, participant_id, timestamp, duration, x_cord, y_cord, token, pupil):
        """Initializes the basic data for each fixation

        Parameters
        ----------
        trial_id : int
            trial id that the fixation belongs to

        participant_id : str
            participant id that the fixation belongs to

        timestamp : int
            fixation time stamp

        duration : int
            fixation duration in milliseconds

        x_cord : float
            fixation x coordinates

        y_cord : float
            fixation y coordinates

        token : str
            the source code token which the fixation is on

        pupil : float
            pupil size of the fixation
        """

        self.trial_id = trial_id
        self.participant_id = participant_id
        self.timestamp = timestamp
        self.duration = duration
        self.x_cord = x_cord
        self.y_cord = y_cord
        self.token = token
        self.pupil = pupil

    def get_fixation(self):
        """Returns fixation attributes as a list

        Returns
        -------
        list
            a list containing fixation information
        """

        return [attribute for attribute in

                [self.trial_id,
                 self.participant_id,
                 self.timestamp,
                 self.duration,
                 self.x_cord,
                 self.y_cord,
                 self.token,
                 self.pupil]

                if attribute is not None]

    def sample_offset(self, x_offset, y_offset):
        """Returns the x and y coordinate of the fixation

        Parameters
        ----------
        x_offset : float
            offset to be applied on all fixations in the x-axis

        y_offset : float
            offset to be applied on all fixations in the y-axis
        """
        self.x_cord += x_offset
        self.y_cord += y_offset

    def __str__(self):
        """Returns string information of fixation

        Returns
        -------
        str
            fixation information
        """
        return f"{self.trial_id} {self.participant_id} {self.timestamp} {self.duration} " \
               f"{self.x_cord} {self.y_cord} {self.token} {self.pupil}"


class Saccade:
    def __init__(self, trial_id, participant_id, timestamp, duration, x_cord, y_cord, x1_cord, y1_cord, amplitude,
                 peak_velocity):
        """Initializes the basic data for each fixation

        Parameters
        ----------
        trial_id : int
            trial id that the fixation belongs to

        participant_id : str
            participant id that the fixation belongs to

        timestamp : int
            saccade start time stamp

        duration : int
            saccade duration in milliseconds

        x_cord : float
            saccade start point x coordinate

        y_cord : float
            saccade start point y coordinate

        x1_cord : float
            saccade end point x coordinate

        y1_cord : float
            saccade end point y coordinate

        amplitude : float
            amplitude for saccade

        peak_velocity : int
            peak velocity during saccade
        """

        self.trial_id = trial_id
        self.participant_id = participant_id
        self.timestamp = timestamp
        self.duration = duration
        self.x_cord = x_cord
        self.y_cord = y_cord
        self.x1_cord = x1_cord
        self.y1_cord = y1_cord
        self.amplitude = amplitude
        self.peak_velocity = peak_velocity

    def get_saccade(self):
        """Returns saccade attributes as a list

        Returns
        -------
        list
            a list containing saccade attributes
        """

        return [self.trial_id,
                self.participant_id,
                self.timestamp,
                self.duration,
                self.x_cord,
                self.y_cord,
                self.x1_cord,
                self.y1_cord,
                self.amplitude,
                self.peak_velocity]

    def sample_offset(self, x_offset, y_offset):
        """Returns the x and y coordinate of the saccade

        Parameters
        ----------
        x_offset : float
            offset to be applied on all fixations in the x-axis

        y_offset : float
            offset to be applied on all fixations in the y-axis
        """
        self.x_cord += x_offset
        self.x1_cord += x_offset
        self.y_cord += y_offset
        self.y1_cord += y_offset

    def __str__(self):
        """Returns string information of saccade

        Returns
        -------
        str
            saccade information
        """
        return f"{self.trial_id} {self.participant_id} {self.timestamp} {self.duration}" \
               f"{self.x_cord} {self.y_cord} {self.x1_cord} {self.y1_cord} {self.amplitude} {self.peak_velocity}"


class Blink:
    def __init__(self, trial_id, participant_id, timestamp, duration):
        """Initializes the basic data for each blink

        Parameters
        ----------
        trial_id : int
            trial id that the blink belongs to

        participant_id : str
            participant id that the blink belongs to

        timestamp : int
            blink time stamp

        duration : int
            blink duration in milliseconds
        """
        self.trial_id = trial_id
        self.participant_id = participant_id
        self.timestamp = timestamp
        self.duration = duration

    def get_blink(self):
        """Returns blink attributes as a list

        Returns
        -------
        list
            a list containing blink attributes
        """

        return [self.trial_id,
                self.participant_id,
                self.timestamp,
                self.duration]

    def __str__(self):
        """Returns string information of blink

        Returns
        -------
        str
            blink information
        """
        return f"{self.trial_id} {self.participant_id} {self.timestamp} {self.duration}"


class Trial:
    """Each trial consists of many samples that need to be converted to fixations.
        A trial is part of an experiment. Or each experiment consists of multiple trials.
    """

    def __init__(self, trial_id: int, participant_id: str, image: str, fixations: dict, saccades: dict, blinks: dict,
                 samples: list, eye_tracker: str):
        """Initializes attributes for storing trial data, fixations, saccades, blinks, and
        stores image name

        Parameters
        ----------
        trial_id : int
            id of this trial

        participant_id : str
            id of this participant

        image : str
            image path for this trial

        fixations : dict
            dictionary that stores fixations as values, order of eye movement in the trial as key

        saccades : dict
            dictionary that stores saccades as values, order of eye movement in the trial as key

        blinks : dict
            dictionary that stores blinks as values, order of eye movement in the trial as key

        samples : list
            list of raw data samples

        eye_tracker : str
            type of eye tracker
        """
        self.trial_id = trial_id
        self.participant_id = participant_id
        self.image = image
        self.fixations = fixations
        self.saccades = saccades
        self.blinks = blinks
        self.samples = samples

        self.offset_history = [[0, 0]]

        self.eye_tracker = eye_tracker

    def get_trial_id(self):
        """Returns the trial id

        Returns
        -------
        int
            trial id
        """
        return self.trial_id

    def get_subject_id(self):
        """Returns the participant id

        Returns
        -------
        str
            participant id
        """
        return self.participant_id

    def get_trial_image(self):
        """Returns the image filename associated with the trial

        Returns
        -------
        str
            the image filename associated with the trial
        """
        return self.image

    def get_fixations(self):
        """Returns the fixations in the trial

        Returns
        -------
        dict
            fixations in the trial
        """
        return self.fixations

    def get_fixation_number(self):
        """Returns the number of fixations in the trial

        Returns
        -------
        int
            number of fixations in the trial
        """
        return len(self.fixations)

    def get_saccades(self):
        """Returns the saccades in the trial

        Returns
        -------
        dict
            saccades in the trial
        """
        return self.saccades

    def get_saccade_number(self):
        """Returns the number of saccades in the trial

        Returns
        -------
        int
            number of saccades in the trial
        """
        return len(self.saccades)

    def get_blinks(self):
        """Returns the blinks in the trial

        Returns
        -------
        dict
            blinks in the trial
        """
        return self.blinks

    def get_blink_number(self):
        """Returns the number of blinks in the trial

        Returns
        -------
        int
            number of blinks in the trial
        """
        return len(self.blinks)

    def get_eye_movement_number(self):
        """Returns the total number of eye movement in the trial

        Returns
        -------
        int
            total number of eye movement
        """
        return self.get_fixation_number() + self.get_saccade_number() + self.get_blink_number()

    def get_samples(self):
        """Returns the raw sample in a list

        Returns
        -------
        list
            a list of raw eye movement samples
        """
        return self.samples

    def get_sample_number(self):
        """Returns the total number of eye movement in the trial

        Returns
        -------
        int
            total number of eye movement
        """
        return len(self.samples)

    def get_offset(self):
        """Returns total offset applied by adding all offsets in offset history

        Returns
        -------
        tuple
            x_offset, y_offset
        """
        return tuple(np.array(self.offset_history).sum(axis=0))

    def reset_offset(self):
        """Resets and changes previously done using offset it implements UNDO feature by
            removing the all applied offset from the offset history.
        """

        x_total, y_total = tuple(np.array(self.offset_history).sum(axis=0) * -1)

        self.sample_offset(x_total, y_total)

        self.offset_history = [[0, 0]]

    def sample_offset(self, x_offset, y_offset):
        """Moves samples +X and +Y pixels across the viewing window to correct fixation shift or
            other shifting problems manually

        Parameters
        ----------
        x_offset : int
            offset to be applied on all fixations in the x-axis

        y_offset : int
            offset to be applied on all fixations in the y-axis
        """
        self.offset_history.append([x_offset, y_offset])

        for order in self.fixations.keys():
            self.fixations[order].sample_offset(x_offset, y_offset)

        for order in self.saccades.keys():
            self.saccades[order].sample_offset(x_offset, y_offset)

        # go over all samples (SMPs) in trial data
        for sample in self.samples:

            if self.eye_tracker == "SMIRed250":
                # Filter MSG samples if any exist, or R eye is inValid

                x_cord, y_cord = float(sample[23]), float(sample[24])

                sample[23] = str(x_cord + x_offset)
                sample[24] = str(y_cord + y_offset)

    def __draw_raw_data(self, draw):
        """Private method that draws raw sample data

        Parameters
        ----------
        draw : PIL.ImageDraw.Draw
            a Draw object imposed on the image
        """

        if self.eye_tracker == "SMIRed250":
            for sample in self.samples:
                # Invalid records
                if len(sample) > 5:
                    x_cord = float(sample[23])
                    y_cord = float(sample[24])  # - 150

                dot_size = 2

                draw.ellipse((x_cord - (dot_size / 2),
                              y_cord - (dot_size / 2),
                              x_cord + dot_size, y_cord + dot_size),
                             fill=(255, 0, 0, 100))

        elif self.eye_tracker == "EyeLink1000":
            return
        return None

    def __draw_fixation(self, draw, draw_number=False):
        """Private method that draws the fixation, also allow user to draw eye movement order

        Parameters
        ----------
        draw : PIL.ImageDraw.Draw
            a Draw object imposed on the image

        draw_number : bool
            whether user wants to draw the eye movement number
        """
        for count, fixation in self.fixations.items():
            duration = fixation.duration
            if 5 * (duration / 100) < 5:
                r = 3
            else:
                r = 5 * (duration / 100)

            x = fixation.x_cord
            y = fixation.y_cord

            bound = (x - r, y - r, x + r, y + r)
            outline_color = (255, 255, 0, 0)
            fill_color = (242, 255, 0, 128)
            draw.ellipse(bound, fill=fill_color, outline=outline_color)

            if draw_number:
                text_bound = (x, y - r / 2)
                text_color = (255, 0, 0, 225)
                draw.text(text_bound, str(count + 2), fill=text_color)

        return None

    def __draw_aoi(self, draw, aoi, bg_color):
        """Private method to draw the Area of Interest on the image

        Parameters
        ----------
        draw : PIL.ImageDraw.Draw
            a Draw object imposed on the image

        aoi : pandas.DataFrame
            a DataFrame that contains the area of interest bounds

        bg_color : str
            background color
        """

        outline = {'white': '#000000', 'black': '#ffffff'}

        for row in aoi[['x', 'y', 'width', 'height']].iterrows():
            y_coordinate = row[1]['y']
            x_coordinate = row[1]['x']
            height = row[1]['height']
            width = row[1]['width']
            draw.rectangle([(x_coordinate, y_coordinate),
                            (x_coordinate + width - 1, y_coordinate + height - 1)],
                           outline=outline[bg_color])

        return None

    def __draw_saccade(self, draw, draw_number=False):
        """

        Parameters
        ----------
        draw : PIL.ImageDraw.Draw
            a Draw object imposed on the image

        draw_number : bool
            whether user wants to draw the eye movement number
        """
        for count, saccade in self.saccades.items():
            x0 = saccade.x_cord
            y0 = saccade.y_cord
            x1 = saccade.x1_cord
            y1 = saccade.y1_cord

            bound = (x0, y0, x1, y1)
            line_color = (122, 122, 0, 255)
            penwidth = 2
            draw.line(bound, fill=line_color, width=penwidth)

            font = ImageFont.truetype('Tohoma.ttf', 16)

            if draw_number:
                text_bound = ((x0 + x1) / 2, (y0 + y1) / 2)
                text_color = 'darkred'
                draw.text(text_bound, str(count + 2), font=font, fill=text_color)

    def draw_trial(self, image_path, draw_raw_data=False, draw_fixation=True, draw_saccade=False, draw_number=False,
                   draw_aoi=None, save_image=None):
        """Draws the trial image and raw-data/fixations over the image
            circle size indicates fixation duration

        image_path : str
            path for trial image file.

        draw_raw_data : bool, optional
            whether user wants raw data drawn.

        draw_fixation : bool, optional
            whether user wants filtered fixations drawn

        draw_saccade : bool, optional
            whether user wants saccades drawn

        draw_number : bool, optional
            whether user wants to draw eye movement number

        draw_aoi : pandas.DataFrame, optional
            Area of Interests

        save_image : str, optional
            path to save the image, image is saved to this path if it parameter exists
        """

        im = Image.open(image_path + self.image)

        if self.eye_tracker == "EyeLink1000":

            background_size = (1024, 768)
            background = Image.new('RGB', background_size, color='black')

            *_, width, _ = im.getbbox()
            # offset = int((1024 - width) / 2) - 10
            trial_location = (10, 375)

            background.paste(im, trial_location, im.convert('RGBA'))

            im = background.copy()


        bg_color = find_background_color(im.copy().convert('1'))

        draw = ImageDraw.Draw(im, 'RGBA')

        if draw_aoi and isinstance(draw_aoi, bool):
            aoi = find_aoi(image=self.image, img=im)
            self.__draw_aoi(draw, aoi, bg_color)

        if isinstance(draw_aoi, pd.DataFrame):
            self.__draw_aoi(draw, draw_aoi, bg_color)

        if draw_raw_data:
            self.__draw_raw_data(draw)

        if draw_fixation:
            self.__draw_fixation(draw, draw_number)

        if draw_saccade:
            self.__draw_saccade(draw, draw_number)

        plt.figure(figsize=(17, 15))
        plt.imshow(np.asarray(im), interpolation='nearest')

        if save_image is not None:
            # Save the image with applied offset

            image_name = save_image + \
                         str(self.participant_id) + \
                         "-t" + \
                         str(self.trial_id) + \
                         "-offsetx" + \
                         str(self.get_offset()[0]) + \
                         "y" + \
                         str(self.get_offset()[1]) + \
                         ".png"

            plt.savefig(image_name)

            print(image_name, "saved!")


class Experiment:
    """Each subject data represents an experiment with multiple trials"""

    def __init__(self, trial: list, eye_tracker: str, filetype: str):
        """Initialize each experiment with raw data file
            This method splits data into a bunch of trials based on JPG

        Parameters
        ----------
        trial: list
            raw data TSV file.

        eye_tracker: str
            type of eye tracker used
            
        filetype : str
            type of the file, e.g. "tsv" or "asc
        """

        self.trial = trial
        self.eye_tracker = eye_tracker
        self.filetype = filetype

    def get_number_of_trials(self):
        """Returns the number of trials in the experiment

        Returns
        -------
        int
            number of trials in the experiment"""
        return len(self.trial)

    def get_eye_tracker(self):
        """Returns the name of eye tracker in the experiment

        Returns
        -------
        str
            name of the eye tracker
        """
        return self.eye_tracker


def idt_classifier(raw_fixations, minimum_duration=50, sample_duration=4, maximum_dispersion=25):
    """I-DT classifier based on page 296 of eye tracker manual:
        https://psychologie.unibas.ch/fileadmin/user_upload/psychologie/Forschung/N-Lab/SMI_iView_X_Manual.pdf

        Notes:
            remember that some data is MSG for mouse clicks.
            some records are invalid with value -1.
            read right eye data only.

    Parameters
    ----------
    raw_fixations : list
        a list of fixations information containing timestamp, x_cord, and y_cord

    minimum_duration : int, optional
        minimum duration for a fixation in milliseconds, less than minimum is considered noise.
        set to 50 milliseconds by default

    sample_duration : int, optional
        Sample duration in milliseconds, this is 4 milliseconds based on this eye tracker

    maximum_dispersion : int, optional
        maximum distance from a group of samples to be considered a single fixation.
        Set to 25 pixels by default

    Returns
    -------
    list
        a list where each element is a list of timestamp, duration, x_cord, and y_cord
    """

    # Create moving window based on minimum_duration
    window_size = int(math.ceil(minimum_duration / sample_duration))

    window_x = []
    window_y = []

    filter_fixation = []

    # Go over all SMPs in trial data
    for timestamp, x_cord, y_cord in raw_fixations:

        # Filter (skip) coordinates outside of the screen 1920×1080 px
        if x_cord < 0 or y_cord < 0 or x_cord > 1920 or y_cord > 1080:
            continue

        # Add sample if it appears to be valid
        window_x.append(x_cord)
        window_y.append(y_cord)

        # Calculate dispersion = [max(x) - min(x)] + [max(y) - min(y)]
        dispersion = (max(window_x) - min(window_x)) + (max(window_y) - min(window_y))

        # If dispersion is above maximum_dispersion
        if dispersion > maximum_dispersion:

            # Then the window does not represent a fixation
            # Pop last item in window
            window_x.pop()
            window_y.pop()

            # Add fixation to fixations if window is not empty (size >= window_size)
            if len(window_x) == len(window_y) and len(window_x) > window_size:
                # The fixation is registered at the centroid of the window points
                filter_fixation.append(
                    [timestamp, len(window_x) * 4, statistics.mean(window_x), statistics.mean(window_y)])

            window_x = []
            window_y = []

    return filter_fixation


def read_SMIRed250(filename, filetype, minimum_duration=50, sample_duration=4, maximum_dispersion=25):
    """Read tsv file from SMI Red 250 eye tracker

    Parameters
    ----------
    filename : str
        name of the tsv file

    filetype : str
        type of the file, e.g. "tsv"

    minimum_duration : int, optional
        minimum duration for a fixation in milliseconds, less than minimum is considered noise.
        set to 50 milliseconds by default.

    sample_duration : int, optional
        Sample duration in milliseconds, this is 4 milliseconds based on this eye tracker.

    maximum_dispersion : int, optional
        maximum distance from a group of samples to be considered a single fixation.
        Set to 25 pixels by default.

    Returns
    -------
    Experiment
        an Experiment object from SMIRed250 data
    """

    # Read raw data file from EMIP dataset
    tsv_file = open(filename)
    print("parsing file:", filename)

    trials = []

    text = tsv_file.read()

    text_lines = text.split('\n')

    active = False  # Indicates whether samples are being recorded in trials
    # The goal is to skip metadata in the file

    trial_id = 0
    participant_id = filename.split('/')[-1].split('_')[0]
    image = ""

    samples = []
    raw_fixations = []

    for line in text_lines:

        token = line.split("\t")

        if len(token) < 3:
            continue

        if active:
            # Filter MSG samples if any exist, or R eye is inValid
            if token[1] == "SMP" and token[27] != "-1":
                # Get x and y for each sample (right eye only)
                # [23] R POR X [px]	 '0.00',
                # [24] R POR Y [px]	 '0.00',
                samples.append(token)
                raw_fixations.append([int(token[0]), float(token[23]), float(token[24])])

        if token[1] == "MSG" and token[3].find(".jpg") != -1:

            if active:
                filter_fixations = idt_classifier(raw_fixations=raw_fixations,
                                                  minimum_duration=minimum_duration,
                                                  sample_duration=sample_duration,
                                                  maximum_dispersion=maximum_dispersion)
                # TODO saccades

                fixations = {}
                count = 0

                for timestamp, duration, x_cord, y_cord in filter_fixations:
                    fixations[count] = Fixation(trial_id=trial_id,
                                                participant_id=participant_id,
                                                timestamp=timestamp,
                                                duration=duration,
                                                x_cord=x_cord,
                                                y_cord=y_cord,
                                                token="",
                                                pupil=0)
                    count += 1

                trials.append(Trial(trial_id=trial_id,
                                    participant_id=participant_id,
                                    image=image,
                                    fixations=fixations,
                                    saccades={},
                                    blinks={},
                                    samples=samples,
                                    eye_tracker="SMIRed250"))

                trial_id += 1

            image = token[3].split(' ')[-1]  # Message: vehicle_java2.jpg

            samples = []
            raw_fixations = []

            active = True

    # Adds the last trial
    filter_fixations = idt_classifier(raw_fixations=raw_fixations,
                                      minimum_duration=minimum_duration,
                                      sample_duration=sample_duration,
                                      maximum_dispersion=maximum_dispersion)

    fixations = {}
    count = 0

    for timestamp, duration, x_cord, y_cord in filter_fixations:
        fixations[count] = Fixation(trial_id=trial_id,
                                    participant_id=participant_id,
                                    timestamp=timestamp,
                                    duration=duration,
                                    x_cord=x_cord,
                                    y_cord=y_cord,
                                    token="",
                                    pupil=0)
        count += 1

    trials.append(Trial(trial_id=trial_id,
                        participant_id=participant_id,
                        image=image,
                        fixations=fixations,
                        saccades={},
                        blinks={},
                        samples=samples,
                        eye_tracker="SMIRed250"))

    return Experiment(trial=trials, eye_tracker="SMIRed250", filetype=filetype)


def read_EyeLink1000(filename, filetype):
    """Read asc file from Eye Link 1000 eye tracker

    Parameters
    ----------
    filename : str
        name of the asc file
        
    filetype : str
        filetype of the file, e.g. "tsv"
        
    Returns
    -------
    Experiment
        an Experiment object of EyeLink1000 data
    """

    asc_file = open(filename)
    print("parsing file:", filename)

    trials = []

    text = asc_file.read()
    text_lines = text.split('\n')

    trial_id = -1
    participant_id = filename.split('.')[0]

    samples = []

    fixations = {}
    saccades = {}
    blinks = {}

    count = 0

    for line in text_lines:

        token = line.split()

        if not token:
            continue

        if "TRIALID" in token:
            # List of eye events
            if trial_id == -1:
                trial_id = int(token[-1])
                continue

            # Read image location
            index = str(int(trial_id) + 1)
            experiment = participant_id.split('/')[-1]
            location = 'runtime/dataviewer/' + experiment + '/graphics/VC_' + index + '.vcl'
            with open(location, 'r') as file:
                image = file.readlines()[1].split()[-3].split('/')[-1]

            # Append fixations and saccades list here
            trials.append(Trial(trial_id=trial_id,
                                participant_id=participant_id,
                                image=image,
                                fixations=fixations,
                                saccades=saccades,
                                blinks=blinks,
                                samples=samples,
                                eye_tracker="EyeLink1000"))

            fixations = {}
            saccades = {}
            blinks = {}
            samples = []
            count = 0
            trial_id = int(token[-1])

        if token[0] == "EFIX":
            timestamp = int(token[2])
            duration = int(token[4])
            x_cord = float(token[5])
            y_cord = float(token[6])
            pupil = int(token[7])

            fixations[count] = Fixation(trial_id=trial_id,
                                        participant_id=participant_id,
                                        timestamp=timestamp,
                                        duration=duration,
                                        x_cord=x_cord,
                                        y_cord=y_cord,
                                        token="",
                                        pupil=pupil)

            samples.append('EFIX' + '    '.join(token))
            count += 1

        if token[0] == "ESACC":
            timestamp = int(token[2])
            duration = int(token[4])
            x_cord = float(token[5]) if token[5] != '.' else 0.0
            y_cord = float(token[6]) if token[6] != '.' else 0.0
            x1_cord = float(token[7]) if token[7] != '.' else 0.0
            y1_cord = float(token[8]) if token[8] != '.' else 0.0
            amplitude = float(token[9])
            peak_velocity = int(token[10])
            saccades[count] = Saccade(trial_id=trial_id,
                                      participant_id=participant_id,
                                      timestamp=timestamp,
                                      duration=duration,
                                      x_cord=x_cord,
                                      y_cord=y_cord,
                                      x1_cord=x1_cord,
                                      y1_cord=y1_cord,
                                      amplitude=amplitude,
                                      peak_velocity=peak_velocity)

            samples.append('ESACC' + '    '.join(token))
            count += 1

        if token[0] == "EBLINK":
            timestamp = int(token[2])
            duration = int(token[4])
            blinks[count] = Blink(trial_id=trial_id,
                                  participant_id=participant_id,
                                  timestamp=timestamp,
                                  duration=duration)

            samples.append('EBLINK' + '    '.join(token))
            count += 1

    # Read image location
    index = str(int(trial_id) + 1)
    experiment = participant_id.split('/')[-1]
    location = 'runtime/dataviewer/' + experiment + '/graphics/VC_' + index + '.vcl'
    with open(location, 'r') as file:
        image = file.readlines()[1].split()[-3].split('/')[-1]

    # Add the last trial
    trials.append(Trial(trial_id=trial_id,
                        participant_id=participant_id,
                        image=image,
                        fixations=fixations,
                        saccades=saccades,
                        blinks=blinks,
                        samples=samples,
                        eye_tracker="EyeLink1000"))

    asc_file.close()

    return Experiment(trial=trials, eye_tracker="EyeLink1000", filetype=filetype)


def find_background_color(img):
    """Private function that identifies the background color of the image

    Parameters
    ----------
    img : PIL.Image
        a PIL (pillow fork) Image object

    Returns
    -------
    str
        the color of the background of the image
    """

    img = img.convert('1')
    width, height = img.size

    color_result = []
    box_size = min(width, height) // 20

    # Move a tiny rectangle box to obtain most common color
    for x, y in zip(range(0, width, box_size), range(0, height, box_size)):
        box = (x, y, x + box_size, y + box_size)
        minimum, maximum = img.crop(box).getextrema()
        color_result.append(minimum)
        color_result.append(maximum)

    # Analyze and determine the background color
    if color_result.count(255) > color_result.count(0):
        bg_color = 'white'
    else:
        bg_color = 'black'

    return bg_color


def find_aoi(image=None, image_path=None, img=None, level="sub-line", margin_height=4, margin_width=7):
    """Find Area of Interest in the given image and store the aoi attributes in a Pandas Dataframe

    Parameters
    ----------
    image : str
        filename for the image, e.g. "vehicle_java.jpg"

    image_path : str
        path for all images, e.g. "emip_dataset/stimuli/"

    img : PIL.Image, optional
        PIL.Image object if user chooses to input an PIL image object

    level : str, optional
        level of detection in AOIs, "line" for each line as an AOI or "sub-line" for each token as an AOI

    margin_height : int, optional
        marginal height when finding AOIs, use smaller number for tight text layout

    margin_width : int, optional
        marginal width when finding AOIs, use smaller number for tight text layout

    Returns
    -------
    pandas.DataFrame
        a pandas DataFrame of area of interest detected by the method
    """

    if img is None:
        if image is None or image_path is None:
            return
        img = Image.open(image_path + image).convert('1')
    else:
        img = img.convert('1')

    width, height = img.size

    # Detect the background color
    bg_color = find_background_color(img)

    left, right = 0, width

    vertical_result, upper_bounds, lower_bounds = [], [], []

    # Move the detecting rectangle from the top to the bottom of the image
    for upper in range(height - margin_height):

        lower = upper + margin_height

        box = (left, upper, right, lower)
        minimum, maximum = img.crop(box).getextrema()

        if upper > 1:
            if bg_color == 'black':
                if vertical_result[-1][3] == 0 and maximum == 255:
                    # Rectangle detects white color for the first time in a while -> Start of one line
                    upper_bounds.append(upper)
                if vertical_result[-1][3] == 255 and maximum == 0:
                    # Rectangle detects black color for the first time in a while -> End of one line
                    lower_bounds.append(lower)
            elif bg_color == 'white':
                if vertical_result[-1][2] == 255 and minimum == 0:
                    # Rectangle detects black color for the first time in a while -> Start of one line
                    upper_bounds.append(upper)
                if vertical_result[-1][2] == 0 and minimum == 255:
                    # Rectangle detects white color for the first time in a while -> End of one line
                    lower_bounds.append(lower)

        # Storing all detection result
        vertical_result.append([upper, lower, minimum, maximum])

    final_result = []

    line_count = 1

    # Iterate through each line of code from detection
    for upper_bound, lower_bound in list(zip(upper_bounds, lower_bounds)):

        # Reset all temporary result for the next line
        horizontal_result, left_bounds, right_bounds = [], [], []

        # Move the detecting rectangle from the left to the right of the image
        for left in range(width - margin_width):

            right = left + margin_width

            box = (left, upper_bound, right, lower_bound)
            minimum, maximum = img.crop(box).getextrema()

            if left > 1:
                if bg_color == 'black':
                    if horizontal_result[-1][3] == 0 and maximum == 255:
                        # Rectangle detects black color for the first time in a while -> Start of one word
                        left_bounds.append(left)
                    if horizontal_result[-1][3] == 255 and maximum == 0:
                        # Rectangle detects white color for the first time in a while -> End of one word
                        right_bounds.append(right)
                elif bg_color == 'white':
                    if horizontal_result[-1][2] == 255 and minimum == 0:
                        # Rectangle detects black color for the first time in a while -> Start of one word
                        left_bounds.append(left)
                    if horizontal_result[-1][2] == 0 and minimum == 255:
                        # Rectangle detects white color for the first time in a while -> End of one word
                        right_bounds.append(right)

            # Storing all detection result
            horizontal_result.append([left, right, minimum, maximum])

        if level == 'sub-line':

            part_count = 1

            for left, right in list(zip(left_bounds, right_bounds)):
                final_result.append(
                    ['sub-line', f'line {line_count} part {part_count}', left, upper_bound, right, lower_bound])
                part_count += 1

        elif level == 'line':
            final_result.append(
                ['line', f'line {line_count}', left_bounds[0], upper_bound, right_bounds[-1], lower_bound])

        line_count += 1

    # Format pandas dataframe
    columns = ['kind', 'name', 'x', 'y', 'width', 'height', 'image']
    aoi = pd.DataFrame(columns=columns)

    for entry in final_result:
        kind, name, x, y, x0, y0 = entry
        width = x0 - x
        height = y0 - y
        image = image

        # For better visualization
        x += margin_width / 2
        width -= margin_width

        value = [kind, name, x, y, width, height, image]
        dic = dict(zip(columns, value))

        aoi = aoi.append(dic, ignore_index=True)

    return aoi


def draw_aoi(aoi, image, image_path):
    """Draws AOI rectangles on to an image.

    Parameters
    ----------
    aoi : pandas.DataFrame
        a pandas DataFrame containing rectangle attributes representing areas of interest (AOIs)

    image : str
        filename for the image where AOI rectangles will be imposed, e.g. "vehicle_java.jpg"

    image_path : str
        path for all images, e.g. "emip_dataset/stimuli/"

    Returns
    -------
    PIL.Image
        a PIL image where AOIs have been drawn as rectangles
    """

    img = Image.open(image_path + image).convert('1')

    bg_color = find_background_color(img)

    outline = {'white': '#000000', 'black': '#ffffff'}

    # copy original image
    rect_image = img.copy()
    draw = ImageDraw.Draw(rect_image)

    # loop over rectangles and draw them
    for row in aoi.iterrows():
        x_coordinate = row[1]['x']
        y_coordinate = row[1]['y']
        height = row[1]['height']
        width = row[1]['width']
        draw.rectangle([(x_coordinate, y_coordinate),
                        (x_coordinate + width - 1, y_coordinate + height - 1)],
                       outline=outline[bg_color])

    return rect_image


def add_tokens_to_AOIs(file_path, aois_raw):
    """Adds tokens from code files to aois dataframe and returns it.

    Parameters
    ----------
    file_path : str
        path to directory where code files are stored. In EMIP this is "emip_stimulus_programs"

    aois_raw : pandas.Dataframe
        the dataframe where AOIs are stored.

    Returns
    -------
    pandas.DataFrame
        a dataframe of AOIs with token information
    """

    image_name = aois_raw["image"][1]

    # rectangle files
    if image_name == "rectangle_java.jpg":
        file_name = "Rectangle.java"

    if image_name == "rectangle_java2.jpg":
        file_name = "Rectangle.java"

    if image_name == "rectangle_python.jpg":
        file_name = "Rectangle.py"

    if image_name == "rectangle_scala.jpg":
        file_name = "Rectangle.scala"

    # vehicle files
    if image_name == "vehicle_java.jpg":
        file_name = "Vehicle.java"

    if image_name == "vehicle_java2.jpg":
        file_name = "Vehicle.java"

    if image_name == "vehicle_python.jpg":
        file_name = "vehicle.py"

    if image_name == "vehicle_scala.jpg":
        file_name = "Vehicle.scala"

    code_file = open(file_path + file_name)

    code_text = code_file.read()

    code_line = code_text.replace('\t', '').replace('        ', '').replace('    ', '').split('\n')

    filtered_line = []

    for line in code_line:
        if len(line) != 0:
            filtered_line.append(line.split(' '))

    # after the code file has been tokenized and indexed
    # we can attach tokens to correct AOI

    aois_raw = aois_raw[aois_raw.kind == "sub-line"].copy()

    tokens = []

    for location in aois_raw["name"].iteritems():
        line_part = location[1].split(' ')
        line_num = int(line_part[1])
        part_num = int(line_part[3])

        # print(line_part, filtered_line[line_num - 1])
        tokens.append(filtered_line[line_num - 1][part_num - 1])

    aois_raw["token"] = tokens

    if aois_raw[aois_raw['token'] == '']['name'].count() != 0:
        print("Error in adding tokens, some tokens are missing!")

    return aois_raw


def add_srcml_to_AOIs(aois_raw, srcML_path):
    """Adds srcML tags to AOIs dataframe and returns it.
        Check https://www.srcml.org/ for more information about srcML

        The files: rectangle.tsv and vehicle.tsv should be in the same directory as the code.

    Parameters
    ----------
    aois_raw : pandas.Dataframe
        the dataframe where AOIs are stored

    srcML_path : string
        the path of the srcML tags file

    Returns
    -------
    pandas.DataFrame
        AOI dataframe with srcML
    """

    image_name = aois_raw["image"][1]

    # srcML rectangle files
    if image_name == "rectangle_java.jpg":
        file_name = "rectangle.tsv"

    if image_name == "rectangle_java2.jpg":
        file_name = "rectangle.tsv"

    if image_name == "rectangle_python.jpg":
        aois_raw["srcML_tag"] = 'na'
        return aois_raw

    if image_name == "rectangle_scala.jpg":
        aois_raw["srcML_tag"] = 'na'
        return aois_raw

    # srcML vehicle files
    if image_name == "vehicle_java.jpg":
        file_name = "vehicle.tsv"

    if image_name == "vehicle_java2.jpg":
        file_name = "vehicle.tsv"

    if image_name == "vehicle_python.jpg":
        aois_raw["srcML_tag"] = 'na'
        return aois_raw

    if image_name == "vehicle_scala.jpg":
        aois_raw["srcML_tag"] = 'na'
        return aois_raw

    srcML_table = pd.read_csv(srcML_path + file_name, sep='\t')

    aois_raw = aois_raw[aois_raw.kind == "sub-line"].copy()

    # after the srcML file has been recognized
    # we can attach tokens to correct AOI

    tags = []

    for location in aois_raw["name"].iteritems():
        found = False

        for srcML_row in srcML_table.itertuples(index=True, name='Pandas'):
            # stimulus_file	token	AOI	syntactic_context

            if srcML_row.AOI == location[1]:
                tags.append(srcML_row.syntactic_context)
                found = True

        if not found:
            tags.append("na")

    aois_raw["srcML_tag"] = tags

    return aois_raw


def overlap(fix, AOI, radius=25):
    """Checks if fixation is within radius distance or over an AOI. Returns True/False.

    Parameters
    ----------
    fix : Fixation
        A single fixation in a trial being considered for overlapping with the AOI

    AOI : pandas.DataFrame
        contains AOI #kind	name	x	y	width	height	local_id	image	token

    radius : int, optional
        radius around AOI to consider fixations in it within the AOI.
        default is 25 pixel since the fixation filter groups samples within 25 pixels.

    Returns
    -------
    bool
        whether it overlaps
    """

    box_x = AOI.x - (radius / 2)
    box_y = AOI.y - (radius / 2)
    box_w = AOI.width + (radius / 2)
    box_h = AOI.height + (radius / 2)

    return box_x <= fix.x_cord <= box_x + box_w and box_y <= fix.y_cord <= box_y + box_h


def hit_test(trial, aois_tokens, radius=25):
    """Checks if fixations are within AOI with a fixation radius of 25 px
        (since each fix is a sum of samples within 25px)

    Parameters
    ----------
    trial : Trial
        contains fixations and other metadata (trial#, participant, code_file, code_language)
            - fixation includes timestamp, duration, x_cord, y_cord

    aois_tokens : pandas.Dataframe
        contains each AOI location and dimension and token text

    radius : int, optional
        radius of circle using in hit test

    Returns
    -------
    pandas.DataFrame
        DataFrame with a record representing each fixation, each record contains:
        trial, participant, code_file, code_language, timestamp, duration, x_cord, y_cord, token, length
    """

    header = ["trial",
              "participant",
              "code_file",
              "code_language",
              "timestamp",
              "duration",
              "x_cord",
              "y_cord",
              "aoi_x",
              "aoi_y",
              "aoi_width",
              "aoi_height",
              "token",
              "length",
              "srcML"]

    result = pd.DataFrame(columns=header)
    print("all fixations:", len(trial.get_fixations()))

    for fix in trial.get_fixations().values():

        for row in aois_tokens.itertuples(index=True, name='Pandas'):
            # kind	name	x	y	width	height	local_id	image	token

            if overlap(fix, row, radius):
                df = pd.DataFrame([[fix.trial_id,
                                    fix.participant_id,
                                    row.image,
                                    row.image,
                                    fix.timestamp,
                                    fix.duration,
                                    fix.x_cord,
                                    fix.y_cord,
                                    row.x,
                                    row.y,
                                    row.width,
                                    row.height,
                                    row.token,
                                    len(row.token),
                                    row.srcML_tag], ], columns=header)

                result = result.append(df, ignore_index=True)

    return result


def EMIP_dataset(path, sample_size=216):
    """Import the EMIP dataset

    Parameters
    ----------
    path : str
        path to EMIP dataset raw data directory, e.g. '../../emip_dataset/rawdata/'

    sample_size : int, optional
        the number of subjects to be processed, the default is 216

    Returns
    -------
    dict
        a dictionary of experiments where the key is the subject ID
    """

    subject = {}
    count = 0

    # go over .tsv files in the rawdata directory add files and count them
    # r = root, d = directories, f = files
    for r, d, f in os.walk(path):
        for file in f:
            if '.tsv' in file:
                participant_id = file.split('/')[-1].split('_')[0]

                if subject.get(participant_id, -1) == -1:
                    subject[participant_id] = read_SMIRed250(os.path.join(r, file), filetype="tsv")
                else:
                    print("Error, experiment already in dictionary")

            count += 1

            # breaks after sample_size
            if count == sample_size:
                break

    return subject


def AlMadi_dataset(path, sample_size=216):
    """Import the Al Madi's dataset

    Parameters
    ----------
    path : str
        path to Al Madi's dataset raw data directory, e.g. '../../AlMadi2018/'

    sample_size : int, optional
        the number of subjects to be processed, the default is 216

    Returns
    -------
    dict
        a dictionary of experiments where the key is the subject ID
    """
    subject = {}
    count = 0

    # go over .tsv files in the rawdata directory add files and count them
    # r = root, d = directories, f = files
    for r, d, f in os.walk(path):
        for file in f:
            if '.asc' in file:

                participant_id = file.split('.')[0]

                if subject.get(participant_id, -1) == -1:
                    subject[participant_id] = read_EyeLink1000(os.path.join(r, file), filetype="asc")
                else:
                    print("Error, experiment already in dictionary")

            count += 1

            # breaks after sample_size
            if count == sample_size:
                break

    return subject


def check_downloaded(dataset_name):
    """Check if the dataset is already in the dataset dictionary

    Parameters
    ----------
    dataset_name : str
        Name of the dataset, path to raw data directory, e.g. '../../dataset_name/'

    Returns
    -------
    bool
        True if dataset is in dataset folder
        False if not

    """
    return os.path.isfile('./datasets/' + dataset_name + '.zip')


def check_unzipped(dataset_name):
    """Check if the dataset is already unzipped in the datasets dictionary

    Parameters
    ----------
    dataset_name : str
        Name of the dataset, path to raw data directory, e.g. '../../dataset_name/'

    Returns
    -------
    bool
        True if dataset is unzipped in dataset folder
        False if not

    """
    return os.path.isdir('./datasets/' + dataset_name)

        
def download(dataset_name):
    """Download any dataset via a link to the data

    Parameters
    ----------
    dataset_name : str
        Name of the dataset, path to raw data directory, e.g. '../../dataset_name/'

    url : str
        link to the data
    
    is_zipped : bool
        True if the url links to a zip file of the data, False if it simply links to the data
    
    citation : str
        link to the paper where the dataset originates from

    """

    url, is_zipped, citation = data_dictionary[dataset_name]

    # Check if dataset has already been downloaded
    if not check_downloaded(dataset_name):
        print("Downloading {}".format(dataset_name))

        #creates a zip file of the data if unzipped
        if is_zipped == False:

            r = requests.get(url)
            path = './datasets/' + dataset_name + '.zip'
            total_length = int(r.headers.get('content-length'))
            with open(path, 'wb') as f:
                f.write(r.content)
                for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length/1024) + 1): 
                    if chunk:
                        f.write(chunk)
                        f.flush()


    if not check_unzipped(dataset_name):
        print('unzipping...')

        #extract all data
        with zipfile.ZipFile('./datasets/' + dataset_name + '.zip', 'r') as data_zip:
            # data_zip.extractall('./datasets/' + dataset_name)

            for member in tqdm(data_zip.infolist(), desc='Extracting '):
                try:
                    data_zip.extract(member, './datasets/' + dataset_name)
                except zipfile.error as e:
                    pass


    print('Please cite this paper: ', citation)

    return './datasets/' + dataset_name